---
title: 'Project Seminar: Probabilistic Forecasting Challenge'
author: "Sebastian Lerch"
subtitle: Programming examples for the temperature and wind speed forecasting tasks
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Preliminaries

Here, I will provide code for loading datasets and implementation examples for the benchmark post-processing models introduced in the lecture.

We will be using the following packages:
```{r}
library(scoringRules)
library(lubridate)
library(crch)
```


# Part 1: Temperature 

We will proceed as follows:

1. load the dataset of historic forecasts and observations
2. fit a simple EMOS model as benchmark (`T_EMOS` in the slides)
3. evaluate the simple EMOS model on the historic data
4. load (an exemplary) current ICON-EU EPS forecast
5. use the EMOS model to make a prediction based on the current ICON-EU EPS forecast

The same steps will be provided for the wind speed task afterwards.

### Loading the historic dataset

After downloading the dataset from ILIAS, we load it via
```{r}
data_dir <- "/home/sebastian/Teaching/2021 WS/Forecasting Challenge Projectseminar/Instructions and examples post-processing/data/"
load(paste0(data_dir, "icon_eps_t_2m.RData"))
t2m_data_raw <- data_icon_eps
rm(data_icon_eps)
```

Examine the contents of the dataset:
```{r}
str(t2m_data_raw)
head(t2m_data_raw)
```

The `data.frame` contains the following columns:

- `init_tm`: time at which the ensemble forecasts were initalized (always at 00 UTC). During the real-time phase of the challenge, those forecasts will be available daily at around 10:30.
- `met_var`: weather variable (only 2-m temperature here) 
- `location`: station location (only Karlsruhe here)
- `fcst_hour`: lead time / horizon of the forecast in hours. Note that the target horizons for the challenge correspond to 36, 48, 60, 72 and 84 h.
- `obs_tm`: time at which the forecast was valid (= `init_tm` + `fcst_hour`)
- `obs`: observed value (at `obs_tm`). In the real-time phase of the challenge, you obviously won't have access to those when making forecasts.
- `ens_1` to `ens_40`: the 40 ensemble member predictions
- `ens_mean`: mean value of the ensemble predictions
- `ens_var`: variance of the ensemble predictions

Every row corresponds to one forecast case. Overall, data exists for the following time range (initialization dates of the NWP model):
```{r}
range(t2m_data_raw$init_tm)
```
Keep in mind that all times are in UTC, which is different from the local time in Karlsruhe.

In the programming examples, we will only consider the lead time of 48 hours:
```{r}
t2m_data <- subset(t2m_data_raw, fcst_hour == 48)

head(t2m_data)
dim(t2m_data)
```

The historic dataset contains 998 dates. There are a few (3) missing observations in the dataset, which we will remove:

```{r}
sum(is.na(t2m_data$obs))
t2m_data <- t2m_data[!is.na(t2m_data$obs),]
```

### Evaluating the (raw, unprocessed) ensemble predictions

To simplify data handling, the `data.frame` is converted into a numerical matrix. We compute the CRPS and look at a verification rank histogram (a discrete analog of a PIT histogram):

```{r}
t2m_ensfc_matrix <- as.matrix(t2m_data[,7:46])

t2m_ens_crps <- crps_sample(y = t2m_data$obs, dat = t2m_ensfc_matrix)
summary(t2m_ens_crps)
```

The mean CRPS for a 48-hour forecast is around 1.2, which is a typical value for ensemble predictions of temperature.

```{r}
t2m_ens_vrh <- sapply(seq_along(1:nrow(t2m_ensfc_matrix)),
                      function(i) rank(c(t2m_data$obs[i], t2m_ensfc_matrix[i,]))[1]) 
hist(t2m_ens_vrh, nclass = 41, freq = F)
```

The ensemble forecasts are clearly severly underdispersed. 

### Implementation of a simple EMOS model 

We will use the simple EMOS model presented in the slides:


\begin{align*} 
y &| \boldsymbol{X}^{\text{t2m}} \sim \mathcal{N}_{{(\mu,\sigma)}}, \\
\mu &= a + b\cdot\text{mean}(\boldsymbol{X}^{\text{t2m}}) \\
\log(\sigma) &= c + d\cdot\text{sd}(\boldsymbol{X}^{\text{t2m}})
\end{align*}

		
As a first step, compute the ensemble standard deviation, which will be used as a predictor: 
```{r}
t2m_data$ens_sd <- sqrt(t2m_data$ens_var)
```

To be able to train and evaluate a model, we split the data into a training and test dataset. In the end, we will estimate a final model based on the entire historic dataset. For now, we use the last year of data as test dataset, and everything before that as training dataset.

```{r}
t2m_data_train <- subset(t2m_data, init_tm <= "2020-09-24")
t2m_data_test <- subset(t2m_data, init_tm >= "2020-09-25")

nrow(t2m_data_train)
nrow(t2m_data_test)
```

To implement the simple EMOS model and estimate the model coefficients, we will use functionality provided by the `crch` package. For more details, see the documentation of the package.

```{r}
t2m_model <- crch(obs ~ ens_mean|ens_sd, # model formula
                  data = t2m_data_train, # dataset
                  dist = "gaussian", # parametric forecast distribution
                  link.scale = "log", # link function for scale parameter
                  type = "crps") # loss function

t2m_model
```

### Evaluate the simple EMOS model based on the historic dataset

Evaluate the ensemble predictions on the test set:
```{r}
t2m_ensfc_matrix_test <- as.matrix(t2m_data_test[,7:46])

t2m_ens_crps_test <- crps_sample(y = t2m_data_test$obs, dat = t2m_ensfc_matrix_test)
mean(t2m_ens_crps_test)
```

To evaluate the EMOS model, we first compute the location and scale parameter on the test dataset, using the model object estimated on the training dataset.

```{r}
t2m_pred_loc <- predict(t2m_model, 
                        t2m_data_test,
                        type = "location")
t2m_pred_sc <- predict(t2m_model, 
                        t2m_data_test,
                        type = "scale")
```

We compute the CRPS to compare to the ensemble:

```{r}
t2m_model_crps_test <- crps(y = t2m_data_test$obs, family = "norm", mean = t2m_pred_loc, sd = t2m_pred_sc) 
mean(t2m_model_crps_test)
```

The simple EMOS model improves the raw ensemble forecasts by about 7%.

To assess calibration, we further look at verification rank and PIT histograms:
```{r}

t2m_ens_vrh_test <- sapply(seq_along(1:nrow(t2m_ensfc_matrix_test)),
                           function(i) rank(c(t2m_data_test$obs[i], t2m_ensfc_matrix_test[i,]))[1]) 

t2m_model_pit_test <- pnorm(t2m_data_test$obs, t2m_pred_loc, t2m_pred_sc)

par(mfrow=c(1,2))
hist(t2m_ens_vrh_test, nclass = 41, freq = F); abline(h = 1/41, lty = 2)
hist(t2m_model_pit_test, nclass = 41, freq = F, ylim = c(0,6)); abline(h = 1, lty = 2)
```

The EMOS model is not perfectly well calibrated, but shows substantial improvements over the underdispersed raw ensemble.

### Estimating the final model

The final benchmark model `T_EMOS` is estimated based on the entire historic dataset.

```{r}
t2m_benchmark2 <- crch(obs ~ ens_mean|ens_sd,
                       data = t2m_data,
                       dist = "gaussian",
                       link.scale = "log", 
                       type = "crps")
```

### Loading the current ensemble forecast 

Current forecasts can be download at https://git.scc.kit.edu/nw5893/kit-weather-ensemble-point-forecast-karlsruhe. The followig example will be based on the file from September 29, 2021.

```{r}
 new_fcst <- read.table(file = paste0(data_dir, "icon-eu-eps_2021092900_t_2m_Karlsruhe.txt"), 
                       sep = "|", 
                       header = TRUE)

# remove empty first and last column
new_fcst[,1] <- NULL
new_fcst[,ncol(new_fcst)] <- NULL

new_fcst
```

Next, we extract the ensemble forecast for the target lead time, and convert it to a numeric vector. 

```{r}
ens_fc <- new_fcst[new_fcst$fcst_hour == 48,][2:ncol(new_fcst)]
ens_fc <- as.numeric(ens_fc)

ens_fc
```

### Making real-time forecasts based on the current ensemble prediction

Target quantile levels:
```{r}
quantile_levels <- c(0.025,0.25,0.5,0.75,0.975)
```

### Benchmark 1: `T_ENS`

As a first benchmark, we will use quantiles from the raw ensemle predictions.

```{r}
t2m_benchmark1_pred <- quantile(ens_fc, quantile_levels)
```

### Benchmark 2: `T_EMOS`

To be able to use the `predict()` method, we first create a `data.frame` that contains the current ensemble mean and standard deviation.

```{r}
pred_df <- data.frame(ens_mean = mean(ens_fc), ens_sd = sd(ens_fc))

t2m_benchmark2_loc <- predict(t2m_benchmark2,
                              pred_df,
                              type = "location")
t2m_benchmark2_sc <- predict(t2m_benchmark2,
                              pred_df,
                              type = "scale")
```

Next, compute target quantiles from the forecast distribution with the EMOS parameters computed above.

```{r}
t2m_benchmark2_pred <- qnorm(quantile_levels, t2m_benchmark2_loc, t2m_benchmark2_sc)
```

Compare the two benchmark models' predictions:
```{r}
rbind(t2m_benchmark1_pred,t2m_benchmark2_pred)
```

Apparently, the EMOS post-processing step leads to a minor shift in the median only, but substantially increases the width of the prediction intervals.

### Accessing (near) real-time observation data

Observation data is not necessarily needed to make predictions, but could be used to better adjust to current conditions, for example using moving-window estimation. The code below illustrates how the `rDWD` package can be used for this purpose. Alternatively, you can directly download data from DWD's OpenData portal (see slides for links).

Installing and using the `rDWD` package can be slightly involved, see https://bookdown.org/brry/rdwd/ for the documentation and examples.

```{r}
library(rdwd)

# obtain a URL object to download the data from
dwd_url <- selectDWD(
  name = "Rheinstetten",
  res = "hourly",
  per = "recent",
  var = "air_temperature"
)

# download the data from the DWD OpenData portal
dataDWD(dwd_url)

# read the downloaded data (note that the file path will differ depending on the operating system)
obs_data <- readDWD("/home/sebastian/DWDdata/hourly_air_temperature_recent_stundenwerte_TU_04177_akt.zip")

# look at the latest available observations
tail(obs_data[,c("MESS_DATUM", "TT_TU")])
```

See https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/hourly/air_temperature/recent/BESCHREIBUNG_obsgermany_climate_hourly_tu_recent_de.pdf for the full documentation of the data. 

Note that you will need to delete the downloaded file to replace it by a newer version when downloading data at a later time.

# Part 2: Wind speed

In the following, the steps from above will be repared for wind speed. The descriptions will be limited to aspects that differ from the first part from above.

### Loading the historic dataset

```{r}
load(paste0(data_dir, "icon_eps_wind_10m.RData"))
wind_data_raw <- data_icon_eps
rm(data_icon_eps)

str(wind_data_raw)

wind_data <- subset(wind_data_raw, fcst_hour == 48)
```

### Evaluating the (raw, unprocessed) ensemble predictions

```{r}
wind_data <- wind_data[!is.na(wind_data$obs),]

wind_ensfc_matrix <- as.matrix(wind_data[,7:46])

wind_ens_crps <- crps_sample(y = wind_data$obs, dat = wind_ensfc_matrix)
summary(wind_ens_crps)

wind_ens_vrh <- sapply(seq_along(1:nrow(wind_ensfc_matrix)),
                      function(i) rank(c(wind_data$obs[i], wind_ensfc_matrix[i,]))[1]) 

hist(wind_ens_vrh, nclass = 41, freq = F)
```

### Implementation of a simple EMOS model 

```{r}
wind_data$ens_sd <- sqrt(wind_data$ens_var)

wind_data_train <- subset(wind_data, init_tm <= "2020-09-24")
wind_data_test <- subset(wind_data, init_tm >= "2020-09-25")

dim(wind_data_train)
dim(wind_data_test)
```

We use a truncated normal distribution for wind speed. Note the `truncated = TRUE` and `left = 0` arguments below which introduce a left-truncation at 0.

\begin{align*} 
y &| \boldsymbol{X}^{\text{ws}} \sim \mathcal{N}^{[0,\infty)}_{{(\mu,\sigma)}}, \\
\mu &= a + b\cdot\text{mean}(\boldsymbol{X}^{\text{ws}}) \\
\log(\sigma) &= c + d\cdot\text{sd}(\boldsymbol{X}^{\text{ws}})
\end{align*}

```{r}
wind_model <- crch(obs ~ ens_mean|ens_sd,
                  data = wind_data_train,
                  dist = "gaussian",
                  left = 0,
                  truncated = TRUE,
                  link.scale = "log", 
                  type = "crps")

wind_model
```

### Evaluate the simple EMOS model based on the historic dataset

```{r}
wind_pred_loc <- predict(wind_model, 
                        wind_data_test,
                        type = "location")
wind_pred_sc <- predict(wind_model, 
                       wind_data_test,
                       type = "scale")

wind_ensfc_matrix_test <- as.matrix(wind_data_test[,7:46])

wind_ens_crps_test <- crps_sample(y = wind_data_test$obs, dat = wind_ensfc_matrix_test)
mean(wind_ens_crps_test)

wind_model_crps_test <- crps(y = wind_data_test$obs, 
                             family = "tnorm", 
                             lower = 0,
                             upper = Inf,
                             location = wind_pred_loc, 
                             scale = wind_pred_sc) 
mean(wind_model_crps_test)
```

Note the adjustments in the `crps()` function here, again introducing a left-truncation at 0. See the documentation of the `scoringRules` package for details and other distributions.

```{r}
wind_ens_vrh_test <- sapply(seq_along(1:nrow(wind_ensfc_matrix_test)),
                           function(i) rank(c(wind_data_test$obs[i], wind_ensfc_matrix_test[i,]))[1]) 

wind_model_pit_test <- ptnorm(wind_data_test$obs, wind_pred_loc, wind_pred_sc, left = 0)

par(mfrow=c(1,2))
hist(wind_ens_vrh_test, nclass = 41, freq = F); abline(h = 1/41, lty = 2)
hist(wind_model_pit_test, nclass = 41, freq = F, ylim = c(0,6)); abline(h = 1, lty = 2)
```

### Estimating the final model

```{r}
wind_benchmark2 <- crch(obs ~ ens_mean|ens_sd,
                        data = wind_data,
                        dist = "gaussian",
                        left = 0,
                        truncated = TRUE,
                        link.scale = "log", 
                        type = "crps")
```

### Loading the current ensemble forecast 

```{r}
new_fcst <- read.table(file = paste0(data_dir, "icon-eu-eps_2021092900_wind_mean_10m_Karlsruhe.txt"), 
                       sep = "|", 
                       header = TRUE)
new_fcst[,1] <- NULL
new_fcst[,ncol(new_fcst)] <- NULL

ens_fc <- new_fcst[new_fcst$fcst_hour == 48,][2:ncol(new_fcst)]
ens_fc <- as.numeric(ens_fc)
```

### Making real-time forecasts based on the current ensemble prediction

### Benchmark 1: `W_ENS`

```{r}
wind_benchmark1_pred <- quantile(ens_fc, quantile_levels) 
```

### Benchmark 2: `W_EMOS`

```{r}
pred_df <- data.frame(ens_mean = mean(ens_fc), ens_sd = sd(ens_fc))

wind_benchmark2_loc <- predict(wind_benchmark2,
                              pred_df,
                              type = "location")
wind_benchmark2_sc <- predict(wind_benchmark2,
                             pred_df,
                             type = "scale")

wind_benchmark2_pred <- qtnorm(quantile_levels, wind_benchmark2_loc, wind_benchmark2_sc, left = 0)

rbind(wind_benchmark1_pred,wind_benchmark2_pred)
```

Note the shift in the median.

### Accessing (near) real-time observation data

```{r}
dwd_url <- selectDWD(
  name = "Rheinstetten",
  res = "hourly",
  per = "recent",
  var = "wind"
)

dataDWD(dwd_url)

obs_data <- readDWD("/home/sebastian/DWDdata/hourly_wind_recent_stundenwerte_FF_04177_akt.zip")

tail(obs_data[,c("MESS_DATUM", "F")])
```

Note that the observation data are in m/s, but the forecast data are in km/h.
